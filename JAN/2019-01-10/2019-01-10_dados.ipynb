{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import statistics as std\n",
    "import pandas as pd                                 \n",
    "import numpy as np                          #Importando os módulos necessários\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "from astropy.io.fits import HDUList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('logfile','r')                       #Abrindo o arquivo com os dados\n",
    "fwhm_1998NU = []                                 #Lista vazia para salvar os valores do fwhm\n",
    "fwhm_2000NG11 = []                               #Lista vazia para salvar os valores do fwhm\n",
    "fwhm_2009SV17_120s = []                          #Lista vazia para salvar os valores do fwhm\n",
    "fwhm_2009SV17_200s = []                          #Lista vazia para salvar os valores do fwhm\n",
    "fwhm_GD108 = []                                  #Lista vazia para salvar os valores do fwhm\n",
    "\n",
    "for indice, linha in enumerate(file):            #Loop para ler as linhas apartir da 480 e pegar o fwhm\n",
    "    if indice >=1 and indice < 104:\n",
    "        if linha[:47] == '  Average full width at half maximum (FWHM) of ': \n",
    "            fwhm_1998NU.append(float(linha[47:]))\n",
    "    elif indice >=104 and indice < 129:\n",
    "        if linha[:47] == '  Average full width at half maximum (FWHM) of ': \n",
    "            fwhm_2000NG11.append(float(linha[47:]))\n",
    "    elif indice >=129 and indice < 144:\n",
    "        if linha[:47] == '  Average full width at half maximum (FWHM) of ': \n",
    "            fwhm_2009SV17_120s.append(float(linha[47:]))\n",
    "    elif indice >=147 and indice <= 170:\n",
    "        if linha[:39] == '  Full width at half maximum (FWHM) of ': \n",
    "            fwhm_2009SV17_200s.append(float(linha[39:]))\n",
    "    elif indice >171:\n",
    "        if linha[:39] == '  Full width at half maximum (FWHM) of ': \n",
    "            fwhm_GD108.append(float(linha[39:]))\n",
    "        elif linha[:47]== '  Average full width at half maximum (FWHM) of ':\n",
    "            fwhm_GD108.append(float(linha[47:]))\n",
    "            \n",
    "fwhm_1998NU = sorted(fwhm_1998NU)\n",
    "fwhm_2000NG11 = sorted(fwhm_2000NG11)\n",
    "fwhm_2009SV17_120s = sorted(fwhm_2009SV17_120s)\n",
    "fwhm_2009SV17_200s = sorted(fwhm_2009SV17_200s)\n",
    "fwhm_GD108 = sorted(fwhm_GD108)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1998NU</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagens usadas no psfmeasure = 1,51,101,151,201,251,301,331\n",
    "\n",
    "name_1998NU = '1998NU/1998NU_40s_b2x2-001_R.fit'\n",
    "imagens_1998NU = []                                                        #Lista com o nome das imagens\n",
    "\n",
    "for i in range(0,331,50):       \n",
    "    if i < 10:                                                      #Para imagens 001 ate 009 \n",
    "        number_1998NU = name_1998NU[23:26].replace(name_1998NU[25],str(int(name_1998NU[25])+i))   \n",
    "        imagens_1998NU.append('1998NU/1998NU_40s_b2x2-' + str(number_1998NU) + '_R.fit' )\n",
    "    elif i >= 10 and i < 100:                                       #Para imagens 010 ate 099 \n",
    "        name_1998NU = '1998NU/1998NU_40s_b2x2-011_R.fit'\n",
    "        number_1998NU = name_1998NU[23:25].replace(name_1998NU[25],str(int(name_1998NU[25])+i))\n",
    "        imagens_1998NU.append('1998NU/1998NU_40s_b2x2-' + str(number_1998NU) + '_R.fit' )\n",
    "for i in range(1,331,50):                                           #Para imagens >100 \n",
    "    if i >= 100 and i < 331:\n",
    "        name_1998NU = '1998NU/1998NU_40s_b2x2-100_R.fit'\n",
    "        number_1998NU = name_1998NU[25:26].replace(name_1998NU[25],str(int(name_1998NU[25])+i))\n",
    "        imagens_1998NU.append('1998NU/1998NU_40s_b2x2-' + str(number_1998NU) + '_R.fit' )\n",
    "       \n",
    "imagens_1998NU.append('1998NU/1998NU_40s_b2x2-331_R.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_obs_1998NU = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_1998NU:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            date_obs_1998NU.append(hdul[0].header['DATE-OBS'])\n",
    "\n",
    "filtro_1998NU = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_1998NU:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            filtro_1998NU.append(hdul[0].header['FILTER'])\n",
    "\n",
    "exp_time_1998NU = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_1998NU:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            exp_time_1998NU.append(hdul[0].header['EXPTIME'])\n",
    "\n",
    "airmass_1998NU = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_1998NU:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            airmass_1998NU.append(hdul[0].header['AIRMASS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_1998NU = {'DATE-OBS':date_obs_1998NU,'EXP-TIME':exp_time_1998NU,'AIRMASS':airmass_1998NU,'FILTER':filtro_1998NU,'FWHM':fwhm_1998NU,'NAME':imagens_1998NU}\n",
    "df_1998NU = pd.DataFrame(data=d_1998NU)\n",
    "df_1998NU = df_1998NU.sort_values(by='DATE-OBS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2000NG11</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagens usadas no psfmeasure = 2,3,4\n",
    "\n",
    "name_2000NG11 = '2000NG11/2000NG11_240s_b2x2-002_R.fit'\n",
    "imagens_2000NG11 = []                                                        #Lista com o nome das imagens\n",
    "\n",
    "for i in range(0,3,1):       \n",
    "    number_2000NG11 = name_2000NG11[28:31].replace(name_2000NG11[30],str(int(name_2000NG11[30])+i))   \n",
    "    imagens_2000NG11.append('2000NG11/2000NG11_240s_b2x2-' + str(number_2000NG11) + '_R.fit' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_obs_2000NG11 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2000NG11:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            date_obs_2000NG11.append(hdul[0].header['DATE-OBS'])\n",
    "\n",
    "filtro_2000NG11 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2000NG11:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            filtro_2000NG11.append(hdul[0].header['FILTER'])\n",
    "\n",
    "exp_time_2000NG11 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2000NG11:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            exp_time_2000NG11.append(hdul[0].header['EXPTIME'])\n",
    "\n",
    "airmass_2000NG11 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2000NG11:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            airmass_2000NG11.append(hdul[0].header['AIRMASS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_2000NG11 = {'DATE-OBS':date_obs_2000NG11,'EXP-TIME':exp_time_2000NG11,'AIRMASS':airmass_2000NG11,'FILTER':filtro_2000NG11,'FWHM':fwhm_2000NG11,'NAME':imagens_2000NG11}\n",
    "df_2000NG11 = pd.DataFrame(data=d_2000NG11)\n",
    "df_2000NG11 = df_2000NG11.sort_values(by='DATE-OBS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2009SV17_120s</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagens usadas no psfmeasure = 1,2\n",
    "\n",
    "name_2009SV17_120s = '2009SV17_120s/2009SV17_120s_b2x2-001_R.fit'\n",
    "imagens_2009SV17_120s = []                                                        #Lista com o nome das imagens\n",
    "\n",
    "for i in range(0,2,1):       \n",
    "    number_2009SV17_120s = name_2009SV17_120s[33:36].replace(name_2009SV17_120s[35],str(int(name_2009SV17_120s[35])+i))   \n",
    "    imagens_2009SV17_120s.append('2009SV17_120s/2009SV17_120s_b2x2-' + str(number_2009SV17_120s) + '_R.fit' )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_obs_2009SV17_120s = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2009SV17_120s:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            date_obs_2009SV17_120s.append(hdul[0].header['DATE-OBS'])\n",
    "\n",
    "filtro_2009SV17_120s = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2009SV17_120s:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            filtro_2009SV17_120s.append(hdul[0].header['FILTER'])\n",
    "\n",
    "exp_time_2009SV17_120s = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2009SV17_120s:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            exp_time_2009SV17_120s.append(hdul[0].header['EXPTIME'])\n",
    "\n",
    "airmass_2009SV17_120s = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2009SV17_120s:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            airmass_2009SV17_120s.append(hdul[0].header['AIRMASS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_2009SV17_120s = {'DATE-OBS':date_obs_2009SV17_120s,'EXP-TIME':exp_time_2009SV17_120s,'AIRMASS':airmass_2009SV17_120s,'FILTER':filtro_2009SV17_120s,'FWHM':fwhm_2009SV17_120s,'NAME':imagens_2009SV17_120s}\n",
    "df_2009SV17_120s = pd.DataFrame(data=d_2009SV17_120s)\n",
    "df_2000NG11 = df_2009SV17_120s.sort_values(by='DATE-OBS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2009SV17_200s</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagens usadas no psfmeasure = 1,2,3,4\n",
    "\n",
    "name_2009SV17_200s = '2009SV17_200s/2009SV17_200s_b2x2-001_R.fit'\n",
    "imagens_2009SV17_200s = []                                                        #Lista com o nome das imagens\n",
    "\n",
    "for i in range(0,4,1):       \n",
    "    number_2009SV17_200s = name_2009SV17_200s[33:36].replace(name_2009SV17_200s[35],str(int(name_2009SV17_200s[35])+i))   \n",
    "    imagens_2009SV17_200s.append('2009SV17_200s/2009SV17_200s_b2x2-' + str(number_2009SV17_200s) + '_R.fit' )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_obs_2009SV17_200s = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2009SV17_200s:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            date_obs_2009SV17_200s.append(hdul[0].header['DATE-OBS'])\n",
    "\n",
    "filtro_2009SV17_200s = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2009SV17_200s:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            filtro_2009SV17_200s.append(hdul[0].header['FILTER'])\n",
    "\n",
    "exp_time_2009SV17_200s = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2009SV17_200s:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            exp_time_2009SV17_200s.append(hdul[0].header['EXPTIME'])\n",
    "\n",
    "airmass_2009SV17_200s = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2009SV17_200s:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            airmass_2009SV17_200s.append(hdul[0].header['AIRMASS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_2009SV17_200s = {'DATE-OBS':date_obs_2009SV17_200s,'EXP-TIME':exp_time_2009SV17_200s,'AIRMASS':airmass_2009SV17_200s,'FILTER':filtro_2009SV17_200s,'FWHM':fwhm_2009SV17_200s,'NAME':imagens_2009SV17_200s}\n",
    "df_2009SV17_200s = pd.DataFrame(data=d_2009SV17_200s)\n",
    "df_2009SV17_200s = df_2009SV17_200s.sort_values(by='DATE-OBS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>GD108</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagens usadas no psfmeasure = 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15\n",
    "\n",
    "name_GD108 = 'GD108/GD108_10s_b2x2-001_R.fit'\n",
    "imagens_GD108 = []                                                        #Lista com o nome das imagens\n",
    "\n",
    "for i in range(0,15,1):\n",
    "    if i < 9:                                                      #Para imagens 001 ate 009 \n",
    "        number_GD108 = name_GD108[22:24].replace(name_GD108[23],str(int(name_GD108[23])+i))   \n",
    "        imagens_GD108.append('GD108/GD108_10s_b2x2-0' + str(number_GD108) + '_R.fit' )\n",
    "\n",
    "for i in range(1,16,1):\n",
    "    if i >= 10:                                       #Para imagens 010 até 015\n",
    "        name_GD108 = 'GD108/GD108_10s_b2x2-010_R.fit'\n",
    "        number_GD108 = name_GD108[23:24].replace(name_GD108[23],str(int(name_GD108[23])+i))\n",
    "        imagens_GD108.append('GD108/GD108_10s_b2x2-0' + str(number_GD108) + '_R.fit' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_obs_GD108 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_GD108:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            date_obs_GD108.append(hdul[0].header['DATE-OBS'])\n",
    "\n",
    "filtro_GD108 = []\n",
    "for i in imagens_GD108:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            filtro_GD108.append(hdul[0].header['FILTER'])\n",
    "\n",
    "exp_time_GD108 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_GD108:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            exp_time_GD108.append(hdul[0].header['EXPTIME'])\n",
    "\n",
    "airmass_GD108 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_GD108:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            airmass_GD108.append(hdul[0].header['AIRMASS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_GD108 = {'DATE-OBS':date_obs_GD108,'EXP-TIME':exp_time_GD108,'AIRMASS':airmass_GD108,'FILTER':filtro_GD108,'FWHM':fwhm_GD108,'NAME':imagens_GD108}\n",
    "df_GD108 = pd.DataFrame(data=d_GD108)\n",
    "df_GD108 = df_GD108.sort_values(by='DATE-OBS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE-OBS</th>\n",
       "      <th>EXP-TIME</th>\n",
       "      <th>AIRMASS</th>\n",
       "      <th>FILTER</th>\n",
       "      <th>FWHM</th>\n",
       "      <th>NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-10T23:59:03</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.706065</td>\n",
       "      <td>R</td>\n",
       "      <td>1.6715</td>\n",
       "      <td>1998NU/1998NU_40s_b2x2-001_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-11T00:34:23</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.474433</td>\n",
       "      <td>R</td>\n",
       "      <td>1.7148</td>\n",
       "      <td>1998NU/1998NU_40s_b2x2-051_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-11T01:11:52</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.321280</td>\n",
       "      <td>R</td>\n",
       "      <td>1.8099</td>\n",
       "      <td>1998NU/1998NU_40s_b2x2-101_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-01-11T01:47:03</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.233214</td>\n",
       "      <td>R</td>\n",
       "      <td>1.8455</td>\n",
       "      <td>1998NU/1998NU_40s_b2x2-151_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-01-11T02:09:47</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.434151</td>\n",
       "      <td>R</td>\n",
       "      <td>1.7043</td>\n",
       "      <td>GD108/GD108_10s_b2x2-001_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-01-11T02:09:59</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.432883</td>\n",
       "      <td>R</td>\n",
       "      <td>1.7070</td>\n",
       "      <td>GD108/GD108_10s_b2x2-002_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-01-11T02:10:11</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.431617</td>\n",
       "      <td>R</td>\n",
       "      <td>1.7285</td>\n",
       "      <td>GD108/GD108_10s_b2x2-003_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-01-11T02:10:24</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.430249</td>\n",
       "      <td>R</td>\n",
       "      <td>1.7372</td>\n",
       "      <td>GD108/GD108_10s_b2x2-004_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-01-11T02:10:35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.429095</td>\n",
       "      <td>R</td>\n",
       "      <td>1.8167</td>\n",
       "      <td>GD108/GD108_10s_b2x2-005_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-11T02:14:16</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.451177</td>\n",
       "      <td>R</td>\n",
       "      <td>2.8023</td>\n",
       "      <td>2009SV17_120s/2009SV17_120s_b2x2-001_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2019-01-11T02:14:16</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.451177</td>\n",
       "      <td>R</td>\n",
       "      <td>2.8023</td>\n",
       "      <td>2009SV17_120s/2009SV17_120s_b2x2-001_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2019-01-11T02:16:18</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.443625</td>\n",
       "      <td>R</td>\n",
       "      <td>2.8329</td>\n",
       "      <td>2009SV17_120s/2009SV17_120s_b2x2-002_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-11T02:16:18</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.443625</td>\n",
       "      <td>R</td>\n",
       "      <td>2.8329</td>\n",
       "      <td>2009SV17_120s/2009SV17_120s_b2x2-002_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019-01-11T02:20:21</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.429170</td>\n",
       "      <td>R</td>\n",
       "      <td>2.1001</td>\n",
       "      <td>2009SV17_200s/2009SV17_200s_b2x2-001_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2019-01-11T02:23:43</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.417750</td>\n",
       "      <td>R</td>\n",
       "      <td>2.1361</td>\n",
       "      <td>2009SV17_200s/2009SV17_200s_b2x2-002_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019-01-11T02:27:05</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.406895</td>\n",
       "      <td>R</td>\n",
       "      <td>2.1361</td>\n",
       "      <td>2009SV17_200s/2009SV17_200s_b2x2-003_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019-01-11T02:30:27</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.396481</td>\n",
       "      <td>R</td>\n",
       "      <td>3.8001</td>\n",
       "      <td>2009SV17_200s/2009SV17_200s_b2x2-004_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-01-11T02:42:46</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.262901</td>\n",
       "      <td>R</td>\n",
       "      <td>1.9117</td>\n",
       "      <td>GD108/GD108_10s_b2x2-006_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-01-11T02:42:58</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.262062</td>\n",
       "      <td>R</td>\n",
       "      <td>1.9221</td>\n",
       "      <td>GD108/GD108_10s_b2x2-007_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-01-11T02:43:10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.261225</td>\n",
       "      <td>R</td>\n",
       "      <td>1.9851</td>\n",
       "      <td>GD108/GD108_10s_b2x2-008_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-01-11T02:43:23</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.260320</td>\n",
       "      <td>R</td>\n",
       "      <td>2.0541</td>\n",
       "      <td>GD108/GD108_10s_b2x2-009_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-01-11T02:43:35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.259487</td>\n",
       "      <td>R</td>\n",
       "      <td>2.0988</td>\n",
       "      <td>GD108/GD108_10s_b2x2-010_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-01-11T03:07:32</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.167690</td>\n",
       "      <td>R</td>\n",
       "      <td>1.8877</td>\n",
       "      <td>1998NU/1998NU_40s_b2x2-201_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-01-11T03:43:33</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.189927</td>\n",
       "      <td>R</td>\n",
       "      <td>2.0123</td>\n",
       "      <td>1998NU/1998NU_40s_b2x2-251_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-01-11T04:05:39</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.046549</td>\n",
       "      <td>R</td>\n",
       "      <td>2.1649</td>\n",
       "      <td>GD108/GD108_10s_b2x2-011_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019-01-11T04:05:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.046271</td>\n",
       "      <td>R</td>\n",
       "      <td>2.2341</td>\n",
       "      <td>GD108/GD108_10s_b2x2-012_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019-01-11T04:06:03</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.045994</td>\n",
       "      <td>R</td>\n",
       "      <td>2.4381</td>\n",
       "      <td>GD108/GD108_10s_b2x2-013_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019-01-11T04:06:16</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.045694</td>\n",
       "      <td>R</td>\n",
       "      <td>2.5581</td>\n",
       "      <td>GD108/GD108_10s_b2x2-014_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019-01-11T04:06:28</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.045419</td>\n",
       "      <td>R</td>\n",
       "      <td>2.5621</td>\n",
       "      <td>GD108/GD108_10s_b2x2-015_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-01-11T04:26:48</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.262700</td>\n",
       "      <td>R</td>\n",
       "      <td>2.2357</td>\n",
       "      <td>1998NU/1998NU_40s_b2x2-301_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-01-11T04:47:51</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.320468</td>\n",
       "      <td>R</td>\n",
       "      <td>2.2517</td>\n",
       "      <td>1998NU/1998NU_40s_b2x2-331_R.fit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               DATE-OBS  EXP-TIME   AIRMASS FILTER    FWHM  \\\n",
       "2   2019-01-10T23:59:03      40.0  1.706065      R  1.6715   \n",
       "3   2019-01-11T00:34:23      40.0  1.474433      R  1.7148   \n",
       "4   2019-01-11T01:11:52      40.0  1.321280      R  1.8099   \n",
       "5   2019-01-11T01:47:03      40.0  1.233214      R  1.8455   \n",
       "10  2019-01-11T02:09:47      10.0  1.434151      R  1.7043   \n",
       "11  2019-01-11T02:09:59      10.0  1.432883      R  1.7070   \n",
       "12  2019-01-11T02:10:11      10.0  1.431617      R  1.7285   \n",
       "13  2019-01-11T02:10:24      10.0  1.430249      R  1.7372   \n",
       "14  2019-01-11T02:10:35      10.0  1.429095      R  1.8167   \n",
       "0   2019-01-11T02:14:16     120.0  1.451177      R  2.8023   \n",
       "29  2019-01-11T02:14:16     120.0  1.451177      R  2.8023   \n",
       "30  2019-01-11T02:16:18     120.0  1.443625      R  2.8329   \n",
       "1   2019-01-11T02:16:18     120.0  1.443625      R  2.8329   \n",
       "25  2019-01-11T02:20:21     200.0  1.429170      R  2.1001   \n",
       "26  2019-01-11T02:23:43     200.0  1.417750      R  2.1361   \n",
       "27  2019-01-11T02:27:05     200.0  1.406895      R  2.1361   \n",
       "28  2019-01-11T02:30:27     200.0  1.396481      R  3.8001   \n",
       "15  2019-01-11T02:42:46      10.0  1.262901      R  1.9117   \n",
       "16  2019-01-11T02:42:58      10.0  1.262062      R  1.9221   \n",
       "17  2019-01-11T02:43:10      10.0  1.261225      R  1.9851   \n",
       "18  2019-01-11T02:43:23      10.0  1.260320      R  2.0541   \n",
       "19  2019-01-11T02:43:35      10.0  1.259487      R  2.0988   \n",
       "6   2019-01-11T03:07:32      40.0  1.167690      R  1.8877   \n",
       "7   2019-01-11T03:43:33      40.0  1.189927      R  2.0123   \n",
       "20  2019-01-11T04:05:39      10.0  1.046549      R  2.1649   \n",
       "21  2019-01-11T04:05:51      10.0  1.046271      R  2.2341   \n",
       "22  2019-01-11T04:06:03      10.0  1.045994      R  2.4381   \n",
       "23  2019-01-11T04:06:16      10.0  1.045694      R  2.5581   \n",
       "24  2019-01-11T04:06:28      10.0  1.045419      R  2.5621   \n",
       "8   2019-01-11T04:26:48      40.0  1.262700      R  2.2357   \n",
       "9   2019-01-11T04:47:51      40.0  1.320468      R  2.2517   \n",
       "\n",
       "                                          NAME  \n",
       "2             1998NU/1998NU_40s_b2x2-001_R.fit  \n",
       "3             1998NU/1998NU_40s_b2x2-051_R.fit  \n",
       "4             1998NU/1998NU_40s_b2x2-101_R.fit  \n",
       "5             1998NU/1998NU_40s_b2x2-151_R.fit  \n",
       "10              GD108/GD108_10s_b2x2-001_R.fit  \n",
       "11              GD108/GD108_10s_b2x2-002_R.fit  \n",
       "12              GD108/GD108_10s_b2x2-003_R.fit  \n",
       "13              GD108/GD108_10s_b2x2-004_R.fit  \n",
       "14              GD108/GD108_10s_b2x2-005_R.fit  \n",
       "0   2009SV17_120s/2009SV17_120s_b2x2-001_R.fit  \n",
       "29  2009SV17_120s/2009SV17_120s_b2x2-001_R.fit  \n",
       "30  2009SV17_120s/2009SV17_120s_b2x2-002_R.fit  \n",
       "1   2009SV17_120s/2009SV17_120s_b2x2-002_R.fit  \n",
       "25  2009SV17_200s/2009SV17_200s_b2x2-001_R.fit  \n",
       "26  2009SV17_200s/2009SV17_200s_b2x2-002_R.fit  \n",
       "27  2009SV17_200s/2009SV17_200s_b2x2-003_R.fit  \n",
       "28  2009SV17_200s/2009SV17_200s_b2x2-004_R.fit  \n",
       "15              GD108/GD108_10s_b2x2-006_R.fit  \n",
       "16              GD108/GD108_10s_b2x2-007_R.fit  \n",
       "17              GD108/GD108_10s_b2x2-008_R.fit  \n",
       "18              GD108/GD108_10s_b2x2-009_R.fit  \n",
       "19              GD108/GD108_10s_b2x2-010_R.fit  \n",
       "6             1998NU/1998NU_40s_b2x2-201_R.fit  \n",
       "7             1998NU/1998NU_40s_b2x2-251_R.fit  \n",
       "20              GD108/GD108_10s_b2x2-011_R.fit  \n",
       "21              GD108/GD108_10s_b2x2-012_R.fit  \n",
       "22              GD108/GD108_10s_b2x2-013_R.fit  \n",
       "23              GD108/GD108_10s_b2x2-014_R.fit  \n",
       "24              GD108/GD108_10s_b2x2-015_R.fit  \n",
       "8             1998NU/1998NU_40s_b2x2-301_R.fit  \n",
       "9             1998NU/1998NU_40s_b2x2-331_R.fit  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_2000NG11,df_1998NU,df_GD108,df_2009SV17_200s,df_2009SV17_120s], ignore_index=True)\n",
    "df = df.sort_values(by='DATE-OBS')\n",
    "df.to_csv('2019-01-10_dados.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
