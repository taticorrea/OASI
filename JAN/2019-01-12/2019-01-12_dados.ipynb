{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import statistics as std\n",
    "import pandas as pd                                 \n",
    "import numpy as np                          #Importando os módulos necessários\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "from astropy.io.fits import HDUList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>750</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('logfile','r')                       #Abrindo o arquivo com os dados\n",
    "fwhm_750 = []\n",
    "fwhm_1998NU = []                                 #Listas vazias para salvar os valores do fwhm\n",
    "fwhm_2000NG11 = []                               \n",
    "fwhm_2003CP20 = []\n",
    "fwhm_2009SV12 = []                          \n",
    "fwhm_2009SV17 = []                          \n",
    "fwhm_2016TL18 = []                                  \n",
    "fwhm_2017BL3 = []\n",
    "fwhm_GD108 = []\n",
    "\n",
    "\n",
    "#750\n",
    "for indice, linha in enumerate(file):            #Loop para ler as linhas apartir da 1\n",
    "    if indice > 1 and indice < 98 :\n",
    "        if linha[:47] == '  Average full width at half maximum (FWHM) of ': \n",
    "            fwhm_750.append(float(linha[47:]))\n",
    "        elif linha[:39] == '  Full width at half maximum (FWHM) of ': \n",
    "            fwhm_750.append(float(linha[39:]))\n",
    "#1998NU  \n",
    "    elif indice > 99 and indice < 231:\n",
    "        if linha[:47] == '  Average full width at half maximum (FWHM) of ': \n",
    "            fwhm_1998NU.append(float(linha[47:]))\n",
    "        elif linha[:39] == '  Full width at half maximum (FWHM) of ': \n",
    "            fwhm_1998NU.append(float(linha[39:]))\n",
    "#200NG11\n",
    "    elif indice > 232 and indice < 334:\n",
    "        if linha[:47] == '  Average full width at half maximum (FWHM) of ': \n",
    "            fwhm_2000NG11.append(float(linha[47:]))\n",
    "        elif linha[:39] == '  Full width at half maximum (FWHM) of ': \n",
    "            fwhm_2000NG11.append(float(linha[39:]))\n",
    "#2003CP20\n",
    "    if indice > 334 and indice < 456 :\n",
    "        if linha[:47] == '  Average full width at half maximum (FWHM) of ': \n",
    "            fwhm_2003CP20.append(float(linha[47:]))\n",
    "        elif linha[:39] == '  Full width at half maximum (FWHM) of ': \n",
    "            fwhm_2003CP20.append(float(linha[39:]))\n",
    "#2009SV12  \n",
    "    elif indice > 457 and indice < 494:\n",
    "        if linha[:47] == '  Average full width at half maximum (FWHM) of ': \n",
    "            fwhm_2009SV12.append(float(linha[47:]))\n",
    "        elif linha[:39] == '  Full width at half maximum (FWHM) of ': \n",
    "            fwhm_2009SV12.append(float(linha[39:]))\n",
    "#2009SV17\n",
    "    elif indice > 495 and indice < 528:\n",
    "        if linha[:47] == '  Average full width at half maximum (FWHM) of ': \n",
    "            fwhm_2009SV17.append(float(linha[47:]))\n",
    "        elif linha[:39] == '  Full width at half maximum (FWHM) of ': \n",
    "            fwhm_2009SV17.append(float(linha[39:]))\n",
    "#2016TL18\n",
    "    if indice > 528 and indice < 593 :\n",
    "        if linha[:47] == '  Average full width at half maximum (FWHM) of ': \n",
    "            fwhm_2016TL18.append(float(linha[47:]))\n",
    "        elif linha[:39] == '  Full width at half maximum (FWHM) of ': \n",
    "            fwhm_2016TL18.append(float(linha[39:]))\n",
    "#2017BL3 \n",
    "    elif indice > 594 and indice < 689:\n",
    "        if linha[:47] == '  Average full width at half maximum (FWHM) of ': \n",
    "            fwhm_2017BL3.append(float(linha[47:]))\n",
    "        elif linha[:39] == '  Full width at half maximum (FWHM) of ': \n",
    "           fwhm_2017BL3.append(float(linha[39:]))\n",
    "#GD108\n",
    "    elif indice > 690:\n",
    "        if linha[:47] == '  Average full width at half maximum (FWHM) of ': \n",
    "            fwhm_GD108.append(float(linha[47:]))\n",
    "        elif linha[:39] == '  Full width at half maximum (FWHM) of ': \n",
    "            fwhm_GD108.append(float(linha[39:]))\n",
    "            \n",
    "fwhm_750 = sorted(fwhm_750)            \n",
    "fwhm_1998NU = sorted(fwhm_1998NU)\n",
    "fwhm_2000NG11 = sorted(fwhm_2000NG11)\n",
    "fwhm_2003CP20 = sorted(fwhm_2003CP20)\n",
    "fwhm_2009SV12 = sorted(fwhm_2009SV12)\n",
    "fwhm_2009SV17 = sorted(fwhm_2009SV17)\n",
    "fwhm_2016TL18 = sorted(fwhm_2016TL18)\n",
    "fwhm_2017BL3 = sorted(fwhm_2017BL3)\n",
    "fwhm_GD108 = sorted(fwhm_GD108)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagens usadas no psfmeasure = 18,28,38,48,58,68,78,88,98,108,118\n",
    "\n",
    "name_750 = '750/750_60s_b2x2-018_R.fit'\n",
    "imagens_750 = []                                                        #Lista com o nome das imagens\n",
    "\n",
    "for i in range(0,120,10):\n",
    "    if i >= 1 and i <100:                                       #Para imagens 010 até 015\n",
    "        name_750 = '750/750_60s_b2x2-018_R.fit'\n",
    "        number_750 = name_750[19:20].replace(name_750[19],str(int(name_750[19])+i))\n",
    "        imagens_750.append('750/750_60s_b2x2-0' + str(number_750) + '_R.fit' )\n",
    "for i in range(100,120,8):\n",
    "    if i > 100 and i < 110:                                       #Para imagens 010 até 015\n",
    "        name_750 = '750/750_60s_b2x2-100_R.fit'\n",
    "        number_750 = name_750[19:20].replace(name_750[19],str(int(name_750[19])+i))\n",
    "        imagens_750.append('750/750_60s_b2x2-' + str(number_750) + '_R.fit' )\n",
    "\n",
    "imagens_750.append('750/750_60s_b2x2-118_R.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_obs_750 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_750:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            date_obs_750.append(hdul[0].header['DATE-OBS'])\n",
    "\n",
    "filtro_750 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_750:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            filtro_750.append(hdul[0].header['FILTER'])\n",
    "\n",
    "exp_time_750 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_750:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            exp_time_750.append(hdul[0].header['EXPTIME'])\n",
    "\n",
    "airmass_750= []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_750:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            airmass_750.append(hdul[0].header['AIRMASS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_750 = {'DATE-OBS':date_obs_750,'EXP-TIME':exp_time_750,'AIRMASS':airmass_750,'FILTER':filtro_750,'FWHM':fwhm_750,'NAME':imagens_750}\n",
    "df_750= pd.DataFrame(data=d_750)\n",
    "df_750 = df_750.sort_values(by='DATE-OBS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1>1998NU</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagens usadas no psfmeasure = 20,40,60,80,100,120,140,160,180,200\n",
    "name_1998NU = '1998NU/1998NU_40s_b2x2-000_R.fit'\n",
    "imagens_1998NU = []                                                        #Lista com o nome das imagens\n",
    "\n",
    "for i in range(20,220,20):       \n",
    "    if i >= 20 and i <=80:                                       \n",
    "        number_1998NU = name_1998NU[24:25].replace(name_1998NU[24],str(int(name_1998NU[24])+i))\n",
    "        imagens_1998NU.append('1998NU/1998NU_40s_b2x2-0' + str(number_1998NU) + '_R.fit' )\n",
    "for i in range(100,220,20):                                           \n",
    "    if i > 80 :\n",
    "        name_1998NU = '1998NU/1998NU_40s_b2x2-000_R.fit'\n",
    "        number_1998NU = name_1998NU[23:24].replace(name_1998NU[23],str(int(name_1998NU[23])+i))\n",
    "        imagens_1998NU.append('1998NU/1998NU_40s_b2x2-' + str(number_1998NU) + '_R.fit' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_obs_1998NU = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_1998NU:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            date_obs_1998NU.append(hdul[0].header['DATE-OBS'])\n",
    "\n",
    "filtro_1998NU = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_1998NU:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            filtro_1998NU.append(hdul[0].header['FILTER'])\n",
    "\n",
    "exp_time_1998NU = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_1998NU:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            exp_time_1998NU.append(hdul[0].header['EXPTIME'])\n",
    "\n",
    "airmass_1998NU = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_1998NU:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            airmass_1998NU.append(hdul[0].header['AIRMASS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_1998NU = {'DATE-OBS':date_obs_1998NU,'EXP-TIME':exp_time_1998NU,'AIRMASS':airmass_1998NU,'FILTER':filtro_1998NU,'FWHM':fwhm_1998NU,'NAME':imagens_1998NU}\n",
    "df_1998NU = pd.DataFrame(data=d_1998NU)\n",
    "df_1998NU = df_1998NU.sort_values(by='DATE-OBS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2000NG11</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagens usadas no psfmeasure = 1,2,3,4,5,6,7,8\n",
    "\n",
    "name_2000NG11 = '2000NG11/2000NG11_60s_b2x2-001_R.fit'\n",
    "imagens_2000NG11 = []                                                        #Lista com o nome das imagens\n",
    "\n",
    "for i in range(0,8,1):       \n",
    "    number_2000NG11 = name_2000NG11[27:30].replace(name_2000NG11[29],str(int(name_2000NG11[29])+i))   \n",
    "    imagens_2000NG11.append('2000NG11/2000NG11_60s_b2x2-' + str(number_2000NG11) + '_R.fit' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_obs_2000NG11 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2000NG11:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            date_obs_2000NG11.append(hdul[0].header['DATE-OBS'])\n",
    "\n",
    "filtro_2000NG11 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2000NG11:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            filtro_2000NG11.append(hdul[0].header['FILTER'])\n",
    "\n",
    "exp_time_2000NG11 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2000NG11:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            exp_time_2000NG11.append(hdul[0].header['EXPTIME'])\n",
    "\n",
    "airmass_2000NG11 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2000NG11:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            airmass_2000NG11.append(hdul[0].header['AIRMASS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_2000NG11 = {'DATE-OBS':date_obs_2000NG11,'EXP-TIME':exp_time_2000NG11,'AIRMASS':airmass_2000NG11,'FILTER':filtro_2000NG11,'FWHM':fwhm_2000NG11,'NAME':imagens_2000NG11}\n",
    "df_2000NG11 = pd.DataFrame(data=d_2000NG11)\n",
    "df_2000NG11 = df_2000NG11.sort_values(by='DATE-OBS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2003CP20</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagens usadas no psfmeasure = 1,2,3,4,5,6,7,8,9,10\n",
    "\n",
    "name_2003CP20 = '2003CP20/2003CP20_60s_b2x2-001_R.fit'\n",
    "imagens_2003CP20 = []                                                        #Lista com o nome das imagens\n",
    "\n",
    "for i in range(0,9,1):       \n",
    "        number_2003CP20 = name_2003CP20[27:30].replace(name_2003CP20[29],str(int(name_2003CP20[29])+i))   \n",
    "        imagens_2003CP20.append('2003CP20/2003CP20_60s_b2x2-' + str(number_2003CP20) + '_R.fit' )\n",
    "\n",
    "imagens_2003CP20.append('2003CP20/2003CP20_60s_b2x2-010_R.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_obs_2003CP20 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2003CP20:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            date_obs_2003CP20.append(hdul[0].header['DATE-OBS'])\n",
    "\n",
    "filtro_2003CP20 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2003CP20:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            filtro_2003CP20.append(hdul[0].header['FILTER'])\n",
    "\n",
    "exp_time_2003CP20 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2003CP20:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            exp_time_2003CP20.append(hdul[0].header['EXPTIME'])\n",
    "\n",
    "airmass_2003CP20= []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2003CP20:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            airmass_2003CP20.append(hdul[0].header['AIRMASS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_2003CP20 = {'DATE-OBS':date_obs_2003CP20,'EXP-TIME':exp_time_2003CP20,'AIRMASS':airmass_2003CP20,'FILTER':filtro_2003CP20,'FWHM':fwhm_2003CP20,'NAME':imagens_2003CP20}\n",
    "df_2003CP20 = pd.DataFrame(data=d_2003CP20)\n",
    "df_2003CP20 = df_2000NG11.sort_values(by='DATE-OBS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2009SV12</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagens usadas no psfmeasure = 1,2,3,4\n",
    "\n",
    "name_2009SV12 = '2009SV12/2009SV12_70s_b2x2-001_R.fit'\n",
    "imagens_2009SV12 = []                                                        #Lista com o nome das imagens\n",
    "\n",
    "for i in range(0,4,1):       \n",
    "    number_2009SV12 = name_2009SV12[27:30].replace(name_2009SV12[29],str(int(name_2009SV12[29])+i))   \n",
    "    imagens_2009SV12.append('2009SV12/2009SV12_70s_b2x2-' + str(number_2009SV12) + '_R.fit' )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_obs_2009SV12 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2009SV12:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            date_obs_2009SV12.append(hdul[0].header['DATE-OBS'])\n",
    "\n",
    "filtro_2009SV12 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2009SV12:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            filtro_2009SV12.append(hdul[0].header['FILTER'])\n",
    "\n",
    "exp_time_2009SV12 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2009SV12:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            exp_time_2009SV12.append(hdul[0].header['EXPTIME'])\n",
    "\n",
    "airmass_2009SV12= []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2009SV12:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            airmass_2009SV12.append(hdul[0].header['AIRMASS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_2009SV12 = {'DATE-OBS':date_obs_2009SV12,'EXP-TIME':exp_time_2009SV12,'AIRMASS':airmass_2009SV12,'FILTER':filtro_2009SV12,'FWHM':fwhm_2009SV12,'NAME':imagens_2009SV12}\n",
    "df_2009SV12 = pd.DataFrame(data=d_2009SV12)\n",
    "df_2009SV12 = df_2009SV12.sort_values(by='DATE-OBS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2009SV17</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagens usadas no psfmeasure = 1,2,3,4\n",
    "\n",
    "name_2009SV17 = '2009SV17/2009SV17_70s_b2x2-001_R.fit'\n",
    "imagens_2009SV17 = []                                                        #Lista com o nome das imagens\n",
    "\n",
    "for i in range(0,4,1):       \n",
    "    number_2009SV17 = name_2009SV17[27:30].replace(name_2009SV17[29],str(int(name_2009SV17[29])+i))   \n",
    "    imagens_2009SV17.append('2009SV17/2009SV17_70s_b2x2-' + str(number_2009SV17) + '_R.fit' )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_obs_2009SV17 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2009SV17:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            date_obs_2009SV17.append(hdul[0].header['DATE-OBS'])\n",
    "\n",
    "filtro_2009SV17= []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2009SV17:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            filtro_2009SV17.append(hdul[0].header['FILTER'])\n",
    "\n",
    "exp_time_2009SV17 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2009SV17:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            exp_time_2009SV17.append(hdul[0].header['EXPTIME'])\n",
    "\n",
    "airmass_2009SV17= []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2009SV17:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            airmass_2009SV17.append(hdul[0].header['AIRMASS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_2009SV17 = {'DATE-OBS':date_obs_2009SV17,'EXP-TIME':exp_time_2009SV17,'AIRMASS':airmass_2009SV17,'FILTER':filtro_2009SV17,'FWHM':fwhm_2009SV17,'NAME':imagens_2009SV17}\n",
    "df_2009SV17= pd.DataFrame(data=d_2009SV17)\n",
    "df_2009SV17 = df_2009SV17.sort_values(by='DATE-OBS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2016TL18</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagens usadas no psfmeasure = 1,4,7,10,13,16,19,22\n",
    "\n",
    "name_2016TL18 = '2016TL18/2016TL18_40s_b2x2-001_NF.fit'\n",
    "imagens_2016TL18 = []                                                        #Lista com o nome das imagens\n",
    "\n",
    "for i in range(0,7,3):       \n",
    "    number_2016TL18 = name_2016TL18[27:30].replace(name_2016TL18[29],str(int(name_2016TL18[29])+i))   \n",
    "    imagens_2016TL18.append('2016TL18/2016TL18_40s_b2x2-' + str(number_2016TL18) + '_NF.fit' )\n",
    "for i in range(10,25,3):  \n",
    "    name_2016TL18 = '2016TL18/2016TL18_40s_b2x2-010_NF.fit'\n",
    "    number_2016TL18 = name_2016TL18[29:30].replace(name_2016TL18[29],str(int(name_2016TL18[29])+i))   \n",
    "    imagens_2016TL18.append('2016TL18/2016TL18_40s_b2x2-0' + str(number_2016TL18) + '_NF.fit' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_obs_2016TL18  = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2016TL18 :                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            date_obs_2016TL18 .append(hdul[0].header['DATE-OBS'])\n",
    "\n",
    "filtro_2016TL18 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2016TL18 :                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            filtro_2016TL18 .append(hdul[0].header['FILTER'])\n",
    "\n",
    "exp_time_2016TL18 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2016TL18:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            exp_time_2016TL18 .append(hdul[0].header['EXPTIME'])\n",
    "\n",
    "airmass_2016TL18 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2016TL18 :                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            airmass_2016TL18 .append(hdul[0].header['AIRMASS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_2016TL18 = {'DATE-OBS':date_obs_2016TL18 ,'EXP-TIME':exp_time_2016TL18,'AIRMASS':airmass_2016TL18,'FILTER':filtro_2016TL18 ,'FWHM':fwhm_2016TL18,'NAME':imagens_2016TL18}\n",
    "df_2016TL18 = pd.DataFrame(data=d_2016TL18 )\n",
    "#df_2016TL18  = df_2016TL18 .sort_values(by='DATE-OBS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2017BL3 </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagens usadas no psfmeasure = 3,6,9,12,15,18\n",
    "\n",
    "name_2017BL3 = '2017BL3/2017BL3_70s_b2x2-003_NF.fit'\n",
    "imagens_2017BL3 = []                                                        #Lista com o nome das imagens\n",
    "\n",
    "for i in range(0,9,3):       \n",
    "    number_2017BL3 = name_2017BL3[25:28].replace(name_2017BL3[27],str(int(name_2017BL3[27])+i))   \n",
    "    imagens_2017BL3.append('2017BL3/2017BL3_70s_b2x2-' + str(number_2017BL3) + '_NF.fit' )\n",
    "for i in range(12,20,3):  \n",
    "    name_2017BL3 = '2017BL3/2017BL3_70s_b2x2-010_NF.fit'\n",
    "    number_2017BL3 = name_2017BL3[25:26].replace(name_2017BL3[27],str(int(name_2017BL3[27])+i))   \n",
    "    imagens_2017BL3.append('2017BL3/2017BL3_70s_b2x2-0' + str(number_2017BL3) + '_NF.fit' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_obs_2017BL3 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2017BL3:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            date_obs_2017BL3.append(hdul[0].header['DATE-OBS'])\n",
    "\n",
    "filtro_2017BL3= []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2017BL3:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            filtro_2017BL3.append(hdul[0].header['FILTER'])\n",
    "\n",
    "exp_time_2017BL3 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2017BL3:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            exp_time_2017BL3.append(hdul[0].header['EXPTIME'])\n",
    "\n",
    "airmass_2017BL3 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_2017BL3:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            airmass_2017BL3.append(hdul[0].header['AIRMASS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_2017BL3 = {'DATE-OBS':date_obs_2017BL3,'EXP-TIME':exp_time_2017BL3,'AIRMASS':airmass_2017BL3,'FILTER':filtro_2017BL3,'FWHM':fwhm_2017BL3,'NAME':imagens_2017BL3}\n",
    "df_2017BL3 = pd.DataFrame(data=d_2017BL3)\n",
    "df_2017BL3 = df_2017BL3.sort_values(by='DATE-OBS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>GD108</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagens usadas no psfmeasure = 1,2,3,4,5,6,7,8,9,10\n",
    "\n",
    "name_GD108 = 'GD108/GD108_10s_b2x2-001_R.fit'\n",
    "imagens_GD108 = []                                                        #Lista com o nome das imagens\n",
    "\n",
    "for i in range(0,9,1):\n",
    "    if i < 9:                                                      #Para imagens 001 ate 009 \n",
    "        number_GD108 = name_GD108[22:24].replace(name_GD108[23],str(int(name_GD108[23])+i))   \n",
    "        imagens_GD108.append('GD108/GD108_10s_b2x2-0' + str(number_GD108) + '_R.fit' )\n",
    "imagens_GD108.append('GD108/GD108_10s_b2x2-010_R.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_obs_GD108 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_GD108:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            date_obs_GD108.append(hdul[0].header['DATE-OBS'])\n",
    "\n",
    "filtro_GD108 = []\n",
    "for i in imagens_GD108:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            filtro_GD108.append(hdul[0].header['FILTER'])\n",
    "\n",
    "exp_time_GD108 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_GD108:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            exp_time_GD108.append(hdul[0].header['EXPTIME'])\n",
    "\n",
    "airmass_GD108 = []                                                #Lista com as datas\n",
    "\n",
    "for i in imagens_GD108:                                        #Iterando dentro da lista com os nomes\n",
    "    with fits.open(i) as hdul:                           #Abrindo cada elemento da lista imagens\n",
    "        for hdu in hdul:                                 #Extraindo o header de cada imagem\n",
    "            airmass_GD108.append(hdul[0].header['AIRMASS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_GD108 = {'DATE-OBS':date_obs_GD108,'EXP-TIME':exp_time_GD108,'AIRMASS':airmass_GD108,'FILTER':filtro_GD108,'FWHM':fwhm_GD108,'NAME':imagens_GD108}\n",
    "df_GD108 = pd.DataFrame(data=d_GD108)\n",
    "df_GD108 = df_GD108.sort_values(by='DATE-OBS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE-OBS</th>\n",
       "      <th>EXP-TIME</th>\n",
       "      <th>AIRMASS</th>\n",
       "      <th>FILTER</th>\n",
       "      <th>FWHM</th>\n",
       "      <th>NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2019-01-12T22:45:01</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.130263</td>\n",
       "      <td>R</td>\n",
       "      <td>1.8677</td>\n",
       "      <td>750/750_60s_b2x2-018_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2019-01-12T22:55:30</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.135750</td>\n",
       "      <td>R</td>\n",
       "      <td>1.9292</td>\n",
       "      <td>750/750_60s_b2x2-028_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2019-01-12T23:06:00</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.143848</td>\n",
       "      <td>R</td>\n",
       "      <td>1.9323</td>\n",
       "      <td>750/750_60s_b2x2-038_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2019-01-12T23:16:28</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.154605</td>\n",
       "      <td>R</td>\n",
       "      <td>1.9364</td>\n",
       "      <td>750/750_60s_b2x2-048_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2019-01-12T23:26:58</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.168216</td>\n",
       "      <td>R</td>\n",
       "      <td>1.9872</td>\n",
       "      <td>750/750_60s_b2x2-058_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-01-13T05:29:13</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.538037</td>\n",
       "      <td>R</td>\n",
       "      <td>2.4276</td>\n",
       "      <td>1998NU/1998NU_40s_b2x2-120_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-01-13T05:43:33</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.632845</td>\n",
       "      <td>R</td>\n",
       "      <td>2.4475</td>\n",
       "      <td>1998NU/1998NU_40s_b2x2-140_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-01-13T05:57:54</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.748169</td>\n",
       "      <td>R</td>\n",
       "      <td>2.4597</td>\n",
       "      <td>1998NU/1998NU_40s_b2x2-160_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-01-13T06:12:14</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.889513</td>\n",
       "      <td>R</td>\n",
       "      <td>2.6034</td>\n",
       "      <td>1998NU/1998NU_40s_b2x2-180_R.fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-01-13T06:26:35</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.065532</td>\n",
       "      <td>R</td>\n",
       "      <td>2.7309</td>\n",
       "      <td>1998NU/1998NU_40s_b2x2-200_R.fit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               DATE-OBS  EXP-TIME   AIRMASS FILTER    FWHM  \\\n",
       "52  2019-01-12T22:45:01      60.0  1.130263      R  1.8677   \n",
       "53  2019-01-12T22:55:30      60.0  1.135750      R  1.9292   \n",
       "54  2019-01-12T23:06:00      60.0  1.143848      R  1.9323   \n",
       "55  2019-01-12T23:16:28      60.0  1.154605      R  1.9364   \n",
       "56  2019-01-12T23:26:58      60.0  1.168216      R  1.9872   \n",
       "..                  ...       ...       ...    ...     ...   \n",
       "13  2019-01-13T05:29:13      40.0  1.538037      R  2.4276   \n",
       "14  2019-01-13T05:43:33      40.0  1.632845      R  2.4475   \n",
       "15  2019-01-13T05:57:54      40.0  1.748169      R  2.4597   \n",
       "16  2019-01-13T06:12:14      40.0  1.889513      R  2.6034   \n",
       "17  2019-01-13T06:26:35      40.0  2.065532      R  2.7309   \n",
       "\n",
       "                                NAME  \n",
       "52        750/750_60s_b2x2-018_R.fit  \n",
       "53        750/750_60s_b2x2-028_R.fit  \n",
       "54        750/750_60s_b2x2-038_R.fit  \n",
       "55        750/750_60s_b2x2-048_R.fit  \n",
       "56        750/750_60s_b2x2-058_R.fit  \n",
       "..                               ...  \n",
       "13  1998NU/1998NU_40s_b2x2-120_R.fit  \n",
       "14  1998NU/1998NU_40s_b2x2-140_R.fit  \n",
       "15  1998NU/1998NU_40s_b2x2-160_R.fit  \n",
       "16  1998NU/1998NU_40s_b2x2-180_R.fit  \n",
       "17  1998NU/1998NU_40s_b2x2-200_R.fit  \n",
       "\n",
       "[69 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_2000NG11,df_1998NU,df_GD108,df_2009SV17,df_2009SV12,df_2003CP20,df_2016TL18,df_750,df_2017BL3], ignore_index=True, sort=False)\n",
    "df = df.sort_values(by='DATE-OBS')\n",
    "df.to_csv('2019-01-12_dados.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "181px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "211.833px",
    "left": "1203.67px",
    "top": "131.8px",
    "width": "188.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
